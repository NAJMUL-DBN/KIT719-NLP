{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b2e73f-4503-4794-8ac9-787b5acf8cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\najmulu\\appdata\\roaming\\python\\python312\\site-packages (4.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\najmulu\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\najmulu\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\najmulu\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\najmulu\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0901b9c0-d876-40f5-8647-ffbacf61b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\najmulu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\najmulu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\najmulu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\najmulu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown, movie_reviews\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c248f7e-f3c2-43c4-becf-69b8ecd6fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1) Training Word2Vec on Brown corpus ===\n",
      "Training Word2Vec (this can take a moment)...\n",
      "Model saved to: C:\\Users\\najmulu\\word2vec_brown.model\n",
      "Model reloaded successfully.\n",
      "Vector for 'king' (dim=100):\n",
      "[ 9.58590060e-02  4.98979241e-01  1.36356652e-01  1.30096570e-01\n",
      " -3.52803797e-01 -1.70505583e-01  3.90085489e-01  3.47632170e-01\n",
      " -4.12792675e-02  1.31814955e-02 -2.67216023e-02 -1.97483420e-01\n",
      " -3.10967416e-01 -3.81479189e-02 -1.21954411e-01 -1.09172881e-01\n",
      "  6.79948106e-02 -3.04841191e-01 -3.16980243e-01 -5.37305892e-01\n",
      "  2.94380635e-01  3.13377470e-01  4.45572764e-01 -1.80112347e-01\n",
      " -1.01373836e-01 -6.58368543e-02 -5.09006679e-01 -1.56280547e-01\n",
      "  2.18618095e-01  1.96103491e-02  4.84882265e-01  1.00269258e-01\n",
      "  2.18198612e-01 -6.70234025e-01  1.68403536e-01  1.82396416e-02\n",
      "  1.54398456e-01  2.05432534e-01 -2.24132627e-01 -1.62212580e-01\n",
      "  1.85362354e-01 -3.61309856e-01  8.63816869e-03  2.18285531e-01\n",
      "  2.46094555e-01 -2.28801189e-04 -2.49191821e-01 -1.50018841e-01\n",
      "  4.89422262e-01  1.57261059e-01  1.65491477e-01 -5.07615626e-01\n",
      " -1.30766779e-01 -1.63305163e-01 -3.41226190e-01  1.29542679e-01\n",
      "  4.17493016e-01 -1.67941824e-02 -1.22918747e-01  5.06254770e-02\n",
      "  1.36444390e-01 -1.03176691e-01  1.91438332e-01 -1.16070928e-02\n",
      "  4.68935035e-02  5.63668787e-01  2.91462570e-01  3.68544966e-01\n",
      " -2.72608012e-01  1.93042547e-01 -2.06331119e-01  1.79167479e-01\n",
      "  2.90247262e-01  1.98717564e-01  2.41593912e-01  7.86249153e-03\n",
      "  2.66583934e-02 -5.58857098e-02 -1.38897553e-01  4.60661948e-02\n",
      " -4.90682155e-01 -2.54011691e-01 -2.68952399e-01  1.43226728e-01\n",
      " -1.92598492e-01 -4.54254210e-01  4.97786462e-01 -4.70587537e-02\n",
      "  5.99165633e-02  2.97267973e-01  5.43294013e-01 -1.63619354e-01\n",
      "  4.85967239e-03 -7.27763325e-02  2.37158939e-01  6.66611791e-02\n",
      "  2.42215618e-01  1.02906629e-01 -1.51376888e-01  2.80925781e-01]\n",
      "Similarity between king and queen: 0.9328780174255371\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 1) Training Word2Vec on Brown corpus ===\")\n",
    "\n",
    "\n",
    "sentences = brown.sents()\n",
    "sentences = [[word.lower() for word in sentence] for sentence in sentences]\n",
    "\n",
    "model_path = \"word2vec_brown.model\"\n",
    "print(\"Training Word2Vec (this can take a moment)...\")\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to: {os.path.abspath(model_path)}\")\n",
    "\n",
    "model = Word2Vec.load(model_path)\n",
    "print(\"Model reloaded successfully.\")\n",
    "\n",
    "if 'king' in model.wv:\n",
    "    vector = model.wv['king']\n",
    "    print(f\"Vector for 'king' (dim={len(vector)}):\\n{vector}\")\n",
    "else:\n",
    "    print(\"The word 'king' is not in the Brown vocabulary with current settings.\")\n",
    "\n",
    "w1, w2 = 'king', 'queen'\n",
    "if w1 in model.wv and w2 in model.wv:\n",
    "    similarity = model.wv.similarity(w1, w2)\n",
    "    print(f\"Similarity between {w1} and {w2}: {similarity}\")\n",
    "else:\n",
    "    print(f\"Cannot compute similarity: missing {'king' if w1 not in model.wv else ''} {'queen' if w2 not in model.wv else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cd5f69-4d3b-4c98-b154-660949f4b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2) Naive Bayes with CountVectorizer on movie reviews ===\n",
      "Accuracy: 0.83\n",
      "\n",
      "Classification report (CountVectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.84      0.83       200\n",
      "         pos       0.84      0.82      0.83       200\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n",
      "Prediction: neg\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 2) Naive Bayes with CountVectorizer on movie reviews ===\")\n",
    "\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "random.shuffle(documents)\n",
    "reviews, labels = zip(*documents)\n",
    "reviews = [\" \".join(tokens) for tokens in reviews]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reviews, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts  = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test_counts)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"\\nClassification report (CountVectorizer):\")\n",
    "print(classification_report(y_test, y_pred, target_names=movie_reviews.categories()))\n",
    "\n",
    "new_review = [\"very bad movie, waste of time.\"]\n",
    "new_review_counts = vectorizer.transform(new_review)\n",
    "prediction = nb_classifier.predict(new_review_counts)\n",
    "print(f'Prediction: {\"pos\" if prediction[0] == \"pos\" else \"neg\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dbb229-8d5d-496e-95f9-5268f46c6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 3) Naive Bayes with TfidfVectorizer (tutorial task) ===\n",
      "Accuracy (TF-IDF): 0.83\n",
      "\n",
      "Classification report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.90      0.84       200\n",
      "         pos       0.88      0.76      0.82       200\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n",
      "Prediction (TF-IDF): neg\n",
      "\n",
      "=== Side-by-side accuracy comparison ===\n",
      "CountVectorizer accuracy: 0.83\n",
      "TfidfVectorizer accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 3) Naive Bayes with TfidfVectorizer (tutorial task) ===\")\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f'Accuracy (TF-IDF): {accuracy_tfidf:.2f}')\n",
    "print(\"\\nClassification report (TF-IDF):\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=movie_reviews.categories()))\n",
    "\n",
    "new_review_tfidf = tfidf_vectorizer.transform([\"very bad movie, waste of time.\"])\n",
    "prediction_tfidf = nb_tfidf.predict(new_review_tfidf)\n",
    "print(f'Prediction (TF-IDF): {\"pos\" if prediction_tfidf[0] == \"pos\" else \"neg\"}')\n",
    "\n",
    "print(\"\\n=== Side-by-side accuracy comparison ===\")\n",
    "print(f\"CountVectorizer accuracy: {accuracy:.2f}\")\n",
    "print(f\"TfidfVectorizer accuracy: {accuracy_tfidf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafbf16-8817-45aa-b5b9-3dccbdd5db1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
